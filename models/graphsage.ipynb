{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import global_mean_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_data(features, labels):\n",
    "    print(features.shape)\n",
    "    # Convert to PyTorch tensors\n",
    "    y = torch.tensor(labels, dtype=torch.float32)\n",
    "    x = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    print(\"y shape: \", y.shape)\n",
    "    # fully connected graph for each graph\n",
    "    edge_index = list(itertools.combinations(range(32), 2))\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Create a list of Data objects\n",
    "    data_list = [Data(x=x[i], edge_index=edge_index, y=y[i]) for i in range(x.shape[0])]\n",
    "    print(len(data_list))\n",
    "\n",
    "    print(data_list[0].x.shape)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 32, 30)\n",
      "y shape:  torch.Size([2304, 2])\n",
      "2304\n",
      "torch.Size([32, 30])\n",
      "(576, 32, 30)\n",
      "y shape:  torch.Size([576, 2])\n",
      "576\n",
      "torch.Size([32, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclasclassen/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Load labels and features\n",
    "y = np.load('../data/label_based_on_movie_classification_movie.npy')\n",
    "x = np.load('../data/eeg_data_no_neutral_PSD_gamma.npy')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = load_graph_data(x_train, y_train)\n",
    "test_data = load_graph_data(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 1 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 2 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 3 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 4 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 5 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 6 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 7 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 8 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 9 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 10 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 11 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 12 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 13 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 14 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 15 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 16 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 17 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 18 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 19 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 20 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 21 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 22 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 23 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 24 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 25 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 26 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 27 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 28 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# print(\"mean_out\", mean_out)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(mean_out, labels)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     47\u001b[0m acc \u001b[38;5;241m=\u001b[39m (mean_out\u001b[38;5;241m.\u001b[39mround()\u001b[38;5;241m==\u001b[39mlabels)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Create the model\n",
    "model = GraphSAGE(30, 1)\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(400):\n",
    "    acc_epoch = []\n",
    "    loss_epoch = []\n",
    "    acc_by_movie_train = {}\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    for data in train_loader:\n",
    "        data, target = data, data.y\n",
    "\n",
    "        labels = target[::2]  \n",
    "        movie_numbers = target[1::2]\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data).squeeze()\n",
    "        out = out.view(_batch_size, 32)\n",
    "        # print(\"out test\", out)    \n",
    "        mean_out = torch.mean(out,dim = 1)\n",
    "\n",
    "        # print(\"mean_out\", mean_out)\n",
    "        \n",
    "        loss = criterion(mean_out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = (mean_out.round()==labels).float().mean()\n",
    "        # print(\"acc\", acc)\n",
    "        acc_epoch.append(acc)\n",
    "        correct += (mean_out.round()==labels).sum()\n",
    "        size += len(labels)\n",
    "\n",
    "        # loss\n",
    "        loss_epoch.append(loss.item())\n",
    "\n",
    "\n",
    "        # Save accuracy by movie\n",
    "        for movie, accuracy in zip(movie_numbers, acc_epoch):\n",
    "            acc_by_movie_train[movie.item()] = accuracy.item()\n",
    "\n",
    "    print(f\"Epoch {epoch} Accuracy: {correct/size}, Loss: {np.mean(loss_epoch)}\")\n",
    "\n",
    "# Testing loop\n",
    "# model.eval() \n",
    "with torch.no_grad():\n",
    "    acc_test = []\n",
    "    acc_by_movie_test = {}\n",
    "    for data in test_loader:\n",
    "        data, target = data, data.y\n",
    "\n",
    "        labels = target[::2]  \n",
    "        movie_numbers = target[1::2]\n",
    "\n",
    "        out = model(data).squeeze()\n",
    "        \n",
    "        out = out.view(_batch_size, 32)\n",
    "        mean_out = torch.mean(out,dim = 1)\n",
    "        \n",
    "        acc = (mean_out.round()==labels).float().mean()\n",
    "        acc_test.append(acc)\n",
    "\n",
    "        for movie, accuracy in zip(movie_numbers, acc_test):\n",
    "            acc_by_movie_test[movie.item()] = accuracy.item()\n",
    "\n",
    "    print('Test Accuracy:', np.mean(acc_test))\n",
    "    print(acc_by_movie_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: 1.0, Accuracy: 0.46875\n",
      "Movie: 2.0, Accuracy: 0.625\n",
      "Movie: 3.0, Accuracy: 0.625\n",
      "Movie: 4.0, Accuracy: 0.46875\n",
      "Movie: 5.0, Accuracy: 0.6875\n",
      "Movie: 6.0, Accuracy: 0.53125\n",
      "Movie: 7.0, Accuracy: 0.65625\n",
      "Movie: 8.0, Accuracy: 0.59375\n",
      "Movie: 9.0, Accuracy: 0.75\n",
      "Movie: 10.0, Accuracy: 0.6875\n",
      "Movie: 11.0, Accuracy: 0.5625\n",
      "Movie: 12.0, Accuracy: 0.625\n",
      "Movie: 17.0, Accuracy: 0.75\n",
      "Movie: 18.0, Accuracy: 0.59375\n",
      "Movie: 19.0, Accuracy: 0.625\n",
      "Movie: 20.0, Accuracy: 0.59375\n",
      "Movie: 21.0, Accuracy: 0.59375\n",
      "Movie: 22.0, Accuracy: 0.59375\n",
      "Movie: 23.0, Accuracy: 0.59375\n",
      "Movie: 24.0, Accuracy: 0.65625\n",
      "Movie: 25.0, Accuracy: 0.65625\n",
      "Movie: 26.0, Accuracy: 0.53125\n",
      "Movie: 27.0, Accuracy: 0.5\n",
      "Movie: 28.0, Accuracy: 0.5625\n",
      "Mean accuracy for the first 12 movies: 0.6067708333333334\n",
      "Mean accuracy for the last 12 movies: 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "for movie, accuracy in sorted(acc_by_movie_test.items()):\n",
    "    print(f\"Movie: {movie}, Accuracy: {accuracy}\")\n",
    "\n",
    "# mean acc for the first 12 movies\n",
    "mean_acc = np.mean([acc_by_movie_test[i] for i in range(1, 13)])\n",
    "print(f\"Mean accuracy for the first 12 movies: {mean_acc}\")\n",
    "\n",
    "# mean acc for the last 12 movies\n",
    "mean_acc = np.mean([acc_by_movie_test[i] for i in range(17, 29)])\n",
    "print(f\"Mean accuracy for the last 12 movies: {mean_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
