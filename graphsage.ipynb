{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_data(features, labels):\n",
    "    print(features.shape)\n",
    "    # Convert to PyTorch tensors\n",
    "    y = torch.tensor(labels, dtype=torch.float32)\n",
    "    x = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    # fully connected graph for each graph\n",
    "    edge_index = list(itertools.combinations(range(32), 2))\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Create a list of Data objects\n",
    "    data_list = [Data(x=x[i], edge_index=edge_index, y=y[i]) for i in range(x.shape[0])]\n",
    "    print(len(data_list))\n",
    "\n",
    "    print(data_list[0].x.shape)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 32, 30)\n",
      "2304\n",
      "torch.Size([32, 30])\n",
      "(576, 32, 30)\n",
      "576\n",
      "torch.Size([32, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclasclassen/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Load labels and features\n",
    "y = np.load('label_valence_no_neutral_PSD_gamma.npy')\n",
    "x = np.load('eeg_data_no_neutral_PSD_gamma.npy')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = load_graph_data(x_train, y_train)\n",
    "test_data = load_graph_data(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mniclas-classen\u001b[0m (\u001b[33mniclasclassen\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/niclasclassen/Code/Master/AML_project_gnn/wandb/run-20240504_170019-6gq2l61v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/niclasclassen/aml_mini_project/runs/6gq2l61v' target=\"_blank\">dark-wookie-1</a></strong> to <a href='https://wandb.ai/niclasclassen/aml_mini_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/niclasclassen/aml_mini_project' target=\"_blank\">https://wandb.ai/niclasclassen/aml_mini_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/niclasclassen/aml_mini_project/runs/6gq2l61v' target=\"_blank\">https://wandb.ai/niclasclassen/aml_mini_project/runs/6gq2l61v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/niclasclassen/aml_mini_project/runs/6gq2l61v?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x15242c050>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"aml_mini_project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"GRAPHSage\",\n",
    "    \"dataset\": \"EEG\",\n",
    "    \"epochs\": 100,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5651042 tensor(0.5312)\n",
      "1 0.5651042 tensor(0.4062)\n",
      "2 0.5651042 tensor(0.4375)\n",
      "3 0.5651042 tensor(0.5312)\n",
      "4 0.5651042 tensor(0.5625)\n",
      "5 0.5651042 tensor(0.4688)\n",
      "6 0.5651042 tensor(0.5938)\n",
      "7 0.5651042 tensor(0.5625)\n",
      "8 0.5651042 tensor(0.5625)\n",
      "9 0.5651042 tensor(0.5625)\n",
      "Test Accuracy: 0.5833333\n"
     ]
    }
   ],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Create the model\n",
    "model = GraphSAGE(30, 32, 1)\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    acc_epoch = []\n",
    "    for data in train_loader:\n",
    "        data, target = data, data.y\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data).squeeze()\n",
    "        \n",
    "        out = out.view(32,32)\n",
    "        mean_out = torch.mean(out,dim = 1)\n",
    "        \n",
    "        loss = criterion(mean_out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = (mean_out.round()==target).float().mean()\n",
    "        acc_epoch.append(acc)\n",
    "\n",
    "    print(epoch, np.mean(acc_epoch), acc_epoch[-1])\n",
    "\n",
    "# Testing loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    acc_test = []\n",
    "    for data in test_loader:\n",
    "        data, target = data, data.y\n",
    "        out = model(data).squeeze()\n",
    "        \n",
    "        out = out.view(32,32)\n",
    "        mean_out = torch.mean(out,dim = 1)\n",
    "        \n",
    "        acc = (mean_out.round()==target).float().mean()\n",
    "        acc_test.append(acc)\n",
    "\n",
    "    print('Test Accuracy:', np.mean(acc_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
