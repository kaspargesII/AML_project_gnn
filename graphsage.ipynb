{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import global_mean_pool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph_data(features, labels):\n",
    "    print(features.shape)\n",
    "    # Convert to PyTorch tensors\n",
    "    y = torch.tensor(labels, dtype=torch.float32)\n",
    "    x = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "    print(\"y shape: \", y.shape)\n",
    "    # fully connected graph for each graph\n",
    "    edge_index = list(itertools.combinations(range(32), 2))\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Create a list of Data objects\n",
    "    data_list = [Data(x=x[i], edge_index=edge_index, y=y[i]) for i in range(x.shape[0])]\n",
    "    print(len(data_list))\n",
    "\n",
    "    print(data_list[0].x.shape)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 32, 30)\n",
      "y shape:  torch.Size([2304, 2])\n",
      "2304\n",
      "torch.Size([32, 30])\n",
      "(576, 32, 30)\n",
      "y shape:  torch.Size([576, 2])\n",
      "576\n",
      "torch.Size([32, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niclasclassen/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Load labels and features\n",
    "y = np.load('label_based_on_movie_classification_movie.npy')\n",
    "x = np.load('eeg_data_no_neutral_PSD_gamma.npy')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = load_graph_data(x_train, y_train)\n",
    "test_data = load_graph_data(x_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy: 0.4366319477558136, Loss: 0.6945497476392322\n",
      "Epoch 1 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 2 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 3 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 4 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 5 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 6 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 7 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 8 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 9 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 10 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 11 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 12 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 13 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 14 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 15 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 16 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 17 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 18 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 19 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 20 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 21 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 22 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 23 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 24 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 25 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 26 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 27 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 28 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 29 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 30 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 31 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 32 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 33 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 34 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 35 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 36 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 37 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 38 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 39 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 40 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 41 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 42 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 43 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 44 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 45 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 46 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 47 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 48 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 49 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 50 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 51 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 52 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 53 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 54 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 55 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 56 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 57 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 58 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 59 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 60 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 61 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 62 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 63 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 64 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 65 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 66 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 67 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 68 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 69 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 70 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 71 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 72 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 73 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 74 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 75 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 76 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 77 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 78 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 79 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 80 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 81 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 82 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 83 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 84 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n",
      "Epoch 85 Accuracy: 0.5651041865348816, Loss: 0.6931471824645996\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     27\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/loader/dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/data/batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/data/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# In case of node-level storages, we add a top-level batch vector it:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (add_batch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stores[\u001b[38;5;241m0\u001b[39m], NodeStorage)\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m stores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcan_infer_num_nodes):\n\u001b[0;32m--> 142\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    143\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m repeat_interleave(repeats, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    144\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mptr \u001b[38;5;241m=\u001b[39m cumsum(torch\u001b[38;5;241m.\u001b[39mtensor(repeats, device\u001b[38;5;241m=\u001b[39mdevice))\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/data/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# In case of node-level storages, we add a top-level batch vector it:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (add_batch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stores[\u001b[38;5;241m0\u001b[39m], NodeStorage)\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m stores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcan_infer_num_nodes):\n\u001b[0;32m--> 142\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m [\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores]\n\u001b[1;32m    143\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m repeat_interleave(repeats, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    144\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mptr \u001b[38;5;241m=\u001b[39m cumsum(torch\u001b[38;5;241m.\u001b[39mtensor(repeats, device\u001b[38;5;241m=\u001b[39mdevice))\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/data/storage.py:423\u001b[0m, in \u001b[0;36mNodeStorage.num_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m N_KEYS:\n\u001b[1;32m    425\u001b[0m         cat_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent()\u001b[38;5;241m.\u001b[39m__cat_dim__(key, value, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Code/Master/AML_project_gnn/.venv/lib/python3.11/site-packages/torch_geometric/data/storage.py:186\u001b[0m, in \u001b[0;36mBaseStorage.items\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mitems\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ItemsView:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mItemsView\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Create the model\n",
    "model = GraphSAGE(30, 1)\n",
    "\n",
    "# Define a loss function and an optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(400):\n",
    "    acc_epoch = []\n",
    "    loss_epoch = []\n",
    "    acc_by_movie_train = {}\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    for data in train_loader:\n",
    "        data, target = data, data.y\n",
    "\n",
    "        labels = target[::2]  \n",
    "        movie_numbers = target[1::2]\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data).squeeze()\n",
    "        out = out.view(_batch_size, 32)\n",
    "        # print(\"out test\", out)    \n",
    "        mean_out = torch.mean(out,dim = 1)\n",
    "\n",
    "        # print(\"mean_out\", mean_out)\n",
    "        \n",
    "        loss = criterion(mean_out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = (mean_out.round()==labels).float().mean()\n",
    "        # print(\"acc\", acc)\n",
    "        acc_epoch.append(acc)\n",
    "        correct += (mean_out.round()==labels).sum()\n",
    "        size += len(labels)\n",
    "\n",
    "        # loss\n",
    "        loss_epoch.append(loss.item())\n",
    "\n",
    "\n",
    "        # Save accuracy by movie\n",
    "        for movie, accuracy in zip(movie_numbers, acc_epoch):\n",
    "            acc_by_movie_train[movie.item()] = accuracy.item()\n",
    "\n",
    "    print(f\"Epoch {epoch} Accuracy: {correct/size}, Loss: {np.mean(loss_epoch)}\")\n",
    "\n",
    "# Testing loop\n",
    "# model.eval() \n",
    "with torch.no_grad():\n",
    "    acc_test = []\n",
    "    acc_by_movie_test = {}\n",
    "    for data in test_loader:\n",
    "        data, target = data, data.y\n",
    "\n",
    "        labels = target[::2]  \n",
    "        movie_numbers = target[1::2]\n",
    "\n",
    "        out = model(data).squeeze()\n",
    "        \n",
    "        out = out.view(_batch_size, 32)\n",
    "        mean_out = torch.mean(out,dim = 1)\n",
    "        \n",
    "        acc = (mean_out.round()==labels).float().mean()\n",
    "        acc_test.append(acc)\n",
    "\n",
    "        for movie, accuracy in zip(movie_numbers, acc_test):\n",
    "            acc_by_movie_test[movie.item()] = accuracy.item()\n",
    "\n",
    "    print('Test Accuracy:', np.mean(acc_test))\n",
    "    print(acc_by_movie_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie: 1.0, Accuracy: 0.46875\n",
      "Movie: 2.0, Accuracy: 0.625\n",
      "Movie: 3.0, Accuracy: 0.625\n",
      "Movie: 4.0, Accuracy: 0.46875\n",
      "Movie: 5.0, Accuracy: 0.6875\n",
      "Movie: 6.0, Accuracy: 0.53125\n",
      "Movie: 7.0, Accuracy: 0.65625\n",
      "Movie: 8.0, Accuracy: 0.59375\n",
      "Movie: 9.0, Accuracy: 0.75\n",
      "Movie: 10.0, Accuracy: 0.6875\n",
      "Movie: 11.0, Accuracy: 0.5625\n",
      "Movie: 12.0, Accuracy: 0.625\n",
      "Movie: 17.0, Accuracy: 0.75\n",
      "Movie: 18.0, Accuracy: 0.59375\n",
      "Movie: 19.0, Accuracy: 0.625\n",
      "Movie: 20.0, Accuracy: 0.59375\n",
      "Movie: 21.0, Accuracy: 0.59375\n",
      "Movie: 22.0, Accuracy: 0.59375\n",
      "Movie: 23.0, Accuracy: 0.59375\n",
      "Movie: 24.0, Accuracy: 0.65625\n",
      "Movie: 25.0, Accuracy: 0.65625\n",
      "Movie: 26.0, Accuracy: 0.53125\n",
      "Movie: 27.0, Accuracy: 0.5\n",
      "Movie: 28.0, Accuracy: 0.5625\n",
      "Mean accuracy for the first 12 movies: 0.6067708333333334\n",
      "Mean accuracy for the last 12 movies: 0.6041666666666666\n"
     ]
    }
   ],
   "source": [
    "for movie, accuracy in sorted(acc_by_movie_test.items()):\n",
    "    print(f\"Movie: {movie}, Accuracy: {accuracy}\")\n",
    "\n",
    "# mean acc for the first 12 movies\n",
    "mean_acc = np.mean([acc_by_movie_test[i] for i in range(1, 13)])\n",
    "print(f\"Mean accuracy for the first 12 movies: {mean_acc}\")\n",
    "\n",
    "# mean acc for the last 12 movies\n",
    "mean_acc = np.mean([acc_by_movie_test[i] for i in range(17, 29)])\n",
    "print(f\"Mean accuracy for the last 12 movies: {mean_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
